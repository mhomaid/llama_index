{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data from Kafka into LlamaIndex\n",
    "\n",
    "This notebook demonstrates how to use the `KafkaReader` class to load data from a Kafka topic into LlamaIndex and perform queries on the indexed data.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before running this notebook, make sure you have the following:\n",
    "\n",
    "- A running Kafka cluster with the specified topic and data available.\n",
    "- The `llama-index` and `confluent-kafka` libraries installed.\n",
    "\n",
    "## Imports\n",
    "\n",
    "First, let's import the necessary classes:\n",
    "\n",
    "```python\n",
    "# from llama_index import VectorStoreIndex\n",
    "from llama_index.readers.kafka import KafkaReader\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.readers.kafka import KafkaReader\n",
    "\n",
    "# Configure the KafkaReader\n",
    "bootstrap_servers = [\"localhost:9092\"]\n",
    "topics = [\"llama_index_test_topic\"]\n",
    "group_id = \"llama_index_test_group\"\n",
    "security_protocol = \"PLAINTEXT\"\n",
    "\n",
    "# Create an instance of KafkaReader\n",
    "reader = KafkaReader(\n",
    "    bootstrap_servers=bootstrap_servers,\n",
    "    topics=topics,\n",
    "    group_id=group_id,\n",
    "    security_protocol=security_protocol,\n",
    ")\n",
    "\n",
    "# Load data from Kafka\n",
    "documents = reader.load()\n",
    "\n",
    "# Create an index using the loaded documents\n",
    "# index = VectorStoreIndex.from_documents(documents)\n",
    "\n",
    "# Query the index\n",
    "# query_engine = index.as_query_engine()\n",
    "# response = query_engine.query(\"What is the main topic of the documents?\")\n",
    "\n",
    "# print(response)\n",
    "\n",
    "# Close the Kafka reader\n",
    "reader.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core import StorageContext, VectorStoreIndex\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.readers.kafka import KafkaReader\n",
    "from IPython.display import Markdown, display\n",
    "import chromadb\n",
    "\n",
    "# Kafka configuration\n",
    "bootstrap_servers = [\"localhost:9092\"]\n",
    "topics = [\"my_topic\"]\n",
    "group_id = \"my_group\"\n",
    "\n",
    "# Load data from Kafka\n",
    "def load_data_from_kafka():\n",
    "    reader = KafkaReader(\n",
    "        bootstrap_servers=bootstrap_servers,\n",
    "        topics=topics,\n",
    "        group_id=group_id,\n",
    "    )\n",
    "    return reader.load()\n",
    "\n",
    "# Create Chroma client and collection\n",
    "chroma_client = chromadb.Client()\n",
    "chroma_collection = chroma_client.create_collection(\"my_collection\")\n",
    "\n",
    "# Define embedding function\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-base-en-v1.5\")\n",
    "\n",
    "# Build index\n",
    "def build_index(data):\n",
    "    vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "    storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "    index = VectorStoreIndex.from_documents(\n",
    "        data, storage_context=storage_context, embed_model=embed_model\n",
    "    )\n",
    "    return index\n",
    "\n",
    "# Query the index\n",
    "def query_index(index):\n",
    "    query_engine = index.as_query_engine()\n",
    "    response = query_engine.query(\"What is the main topic of the documents?\")\n",
    "    display(Markdown(f\"Query Response: {response}\"))\n",
    "\n",
    "# Update metadata\n",
    "def update_metadata(chroma_collection):\n",
    "    doc_to_update = chroma_collection.get(limit=1)\n",
    "    doc_to_update[\"metadatas\"][0] = {\n",
    "        **doc_to_update[\"metadatas\"][0],\n",
    "        **{\"source\": \"Kafka\"},\n",
    "    }\n",
    "    chroma_collection.update(\n",
    "        ids=[doc_to_update[\"ids\"][0]],\n",
    "        metadatas=[doc_to_update[\"metadatas\"][0]]\n",
    "    )\n",
    "    updated_doc = chroma_collection.get(limit=1)\n",
    "    print(\"Updated Metadata:\", updated_doc[\"metadatas\"][0])\n",
    "\n",
    "# Delete document\n",
    "def delete_document(chroma_collection):\n",
    "    doc_to_delete = chroma_collection.get(limit=1)\n",
    "    print(\"Count before deletion:\", chroma_collection.count())\n",
    "    chroma_collection.delete(ids=[doc_to_delete[\"ids\"][0]])\n",
    "    print(\"Count after deletion:\", chroma_collection.count())\n",
    "\n",
    "def main():\n",
    "    # Load data from Kafka\n",
    "    data = load_data_from_kafka()\n",
    "\n",
    "    # Build index\n",
    "    index = build_index(data)\n",
    "\n",
    "    # Query the index\n",
    "    query_index(index)\n",
    "\n",
    "    # Update metadata\n",
    "    update_metadata(chroma_collection)\n",
    "\n",
    "    # Delete document\n",
    "    delete_document(chroma_collection)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core import StorageContext, VectorStoreIndex, SimpleDirectoryReader, Settings\n",
    "from llama_index.core.embeddings import resolve_embed_model\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.readers.kafka import KafkaReader\n",
    "import chromadb\n",
    "\n",
    "# Kafka configuration\n",
    "bootstrap_servers = [\"localhost:9092\"]\n",
    "topics = [\"my_topic\"]\n",
    "group_id = \"my_group\"\n",
    "\n",
    "# Load data from Kafka\n",
    "def load_data_from_kafka():\n",
    "    reader = KafkaReader(\n",
    "        bootstrap_servers=bootstrap_servers,\n",
    "        topics=topics,\n",
    "        group_id=group_id,\n",
    "    )\n",
    "    return reader.load()\n",
    "\n",
    "# Create Chroma client and collection\n",
    "chroma_client = chromadb.Client()\n",
    "chroma_collection = chroma_client.create_collection(\"my_collection\")\n",
    "\n",
    "# Configure local embedding model and LLM\n",
    "Settings.embed_model = resolve_embed_model(\"local:BAAI/bge-small-en-v1.5\")\n",
    "Settings.llm = Ollama(model=\"mistral\", request_timeout=30.0)\n",
    "\n",
    "# Build index\n",
    "def build_index(data):\n",
    "    vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "    storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "    index = VectorStoreIndex.from_documents(\n",
    "        data, storage_context=storage_context\n",
    "    )\n",
    "    return index\n",
    "\n",
    "# Query the index\n",
    "def query_index(index):\n",
    "    query_engine = index.as_query_engine()\n",
    "    response = query_engine.query(\"What is the main topic of the documents?\")\n",
    "    print(\"Query Response:\", response)\n",
    "\n",
    "# Update metadata\n",
    "def update_metadata(chroma_collection):\n",
    "    doc_to_update = chroma_collection.get(limit=1)\n",
    "    doc_to_update[\"metadatas\"][0] = {\n",
    "        **doc_to_update[\"metadatas\"][0],\n",
    "        **{\"source\": \"Kafka\"},\n",
    "    }\n",
    "    chroma_collection.update(\n",
    "        ids=[doc_to_update[\"ids\"][0]],\n",
    "        metadatas=[doc_to_update[\"metadatas\"][0]]\n",
    "    )\n",
    "    updated_doc = chroma_collection.get(limit=1)\n",
    "    print(\"Updated Metadata:\", updated_doc[\"metadatas\"][0])\n",
    "\n",
    "# Delete document\n",
    "def delete_document(chroma_collection):\n",
    "    doc_to_delete = chroma_collection.get(limit=1)\n",
    "    print(\"Count before deletion:\", chroma_collection.count())\n",
    "    chroma_collection.delete(ids=[doc_to_delete[\"ids\"][0]])\n",
    "    print(\"Count after deletion:\", chroma_collection.count())\n",
    "\n",
    "def main():\n",
    "    # Load data from Kafka\n",
    "    data = load_data_from_kafka()\n",
    "\n",
    "    # Build index\n",
    "    index = build_index(data)\n",
    "\n",
    "    # Query the index\n",
    "    query_index(index)\n",
    "\n",
    "    # Update metadata\n",
    "    update_metadata(chroma_collection)\n",
    "\n",
    "    # Delete document\n",
    "    delete_document(chroma_collection)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama-index-readers-kafka-P1KXr6uQ-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
